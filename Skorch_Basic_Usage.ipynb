{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Skorch Basic usage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*`skorch`* is designed to maximize interoperability between `sklearn` and `pytorch`. The aim is to keep 99% of the flexibility of `pytorch` while being able to leverage most features of `sklearn`. Below, we show the basic usage of `skorch` and how it can be combined with `sklearn`.\n",
    "\n",
    "<table align=\"left\"><td>\n",
    "<a target=\"_blank\" href=\"https://colab.research.google.com/github/skorch-dev/skorch/blob/master/notebooks/Basic_Usage.ipynb\">\n",
    "    <img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>  \n",
    "</td><td>\n",
    "<a target=\"_blank\" href=\"https://github.com/skorch-dev/skorch/blob/master/notebooks/Basic_Usage.ipynb\"><img width=32px src=\"https://www.tensorflow.org/images/GitHub-Mark-32px.png\" />View source on GitHub</a></td></table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows you how to use the basic functionality of `skorch`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Definition of the pytorch module](#Definition-of-the-pytorch-module)\n",
    "* [Training a classifier](#Training-a-classifier-and-making-predictions)\n",
    "  * [Dataset](#A-toy-binary-classification-task)\n",
    "  * [pytorch module](#Definition-of-the-pytorch-classification-module)\n",
    "  * [Model training](#Defining-and-training-the-neural-net-classifier)\n",
    "  * [Inference](#Making-predictions,-classification)\n",
    "* [Training a regressor](#Training-a-regressor)\n",
    "  * [Dataset](#A-toy-regression-task)\n",
    "  * [pytorch module](#Definition-of-the-pytorch-regression-module)\n",
    "  * [Model training](#Defining-and-training-the-neural-net-regressor)\n",
    "  * [Inference](#Making-predictions,-regression)\n",
    "* [Saving and loading a model](#Saving-and-loading-a-model)\n",
    "  * [Whole model](#Saving-the-whole-model)\n",
    "  * [Only parameters](#Saving-only-the-model-parameters)\n",
    "* [Usage with an sklearn Pipeline](#Usage-with-an-sklearn-Pipeline)\n",
    "* [Callbacks](#Callbacks)\n",
    "* [Grid search](#Usage-with-sklearn-GridSearchCV)\n",
    "  * [Special prefixes](#Special-prefixes)\n",
    "  * [Performing a grid search](#Performing-a-grid-search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#! [ ! -z \"$COLAB_GPU\" ] && pip install torch skorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a classifier and making predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A toy binary classification task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load a toy classification task from `sklearn`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(1000, 20, n_informative=10, random_state=0)\n",
    "X, y = X.astype(np.float32), y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 20), (1000,), 0.5)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the `pytorch` classification `module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a vanilla neural network with two hidden layers. The output layer should have 2 output units since there are two classes. In addition, it should have a softmax nonlinearity, because later, when calling `predict_proba`, the output from the `forward` call will be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10,\n",
    "            nonlin=F.relu,\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and training the neural net classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `NeuralNetClassifier` because we're dealing with a classifcation task. The first argument should be the `pytorch module`. As additional arguments, we pass the number of epochs and the learning rate (`lr`), but those are optional.\n",
    "\n",
    "*Note*: To use the CUDA backend, pass `device='cuda'` as an additional argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "#     device='cuda',  # uncomment this to train with CUDA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As in `sklearn`, we call `fit` passing the input data `X` and the targets `y`. By default, `NeuralNetClassifier` makes a `StratifiedKFold` split on the data (80/20) to track the validation loss. This is shown, as well as the train loss and the accuracy on the validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6905\u001b[0m       \u001b[32m0.6150\u001b[0m        \u001b[35m0.6749\u001b[0m  0.0145\n",
      "      2        \u001b[36m0.6740\u001b[0m       \u001b[32m0.6200\u001b[0m        \u001b[35m0.6668\u001b[0m  0.0150\n",
      "      3        \u001b[36m0.6594\u001b[0m       \u001b[32m0.6750\u001b[0m        \u001b[35m0.6554\u001b[0m  0.0147\n",
      "      4        \u001b[36m0.6482\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.6452\u001b[0m  0.0156\n",
      "      5        \u001b[36m0.6423\u001b[0m       \u001b[32m0.7050\u001b[0m        \u001b[35m0.6333\u001b[0m  0.0132\n",
      "      6        \u001b[36m0.6231\u001b[0m       0.7000        \u001b[35m0.6188\u001b[0m  0.0153\n",
      "      7        \u001b[36m0.6081\u001b[0m       \u001b[32m0.7100\u001b[0m        \u001b[35m0.6064\u001b[0m  0.0159\n",
      "      8        \u001b[36m0.6003\u001b[0m       0.7000        \u001b[35m0.5940\u001b[0m  0.0152\n",
      "      9        \u001b[36m0.5937\u001b[0m       \u001b[32m0.7250\u001b[0m        \u001b[35m0.5836\u001b[0m  0.0139\n",
      "     10        \u001b[36m0.5830\u001b[0m       0.7150        \u001b[35m0.5725\u001b[0m  0.0149\n",
      "     11        \u001b[36m0.5686\u001b[0m       0.7100        \u001b[35m0.5660\u001b[0m  0.0141\n",
      "     12        0.5701       0.7150        \u001b[35m0.5577\u001b[0m  0.0168\n",
      "     13        0.5751       0.7200        \u001b[35m0.5499\u001b[0m  0.0149\n",
      "     14        \u001b[36m0.5662\u001b[0m       0.7250        \u001b[35m0.5438\u001b[0m  0.0156\n",
      "     15        \u001b[36m0.5422\u001b[0m       0.7250        \u001b[35m0.5354\u001b[0m  0.0150\n",
      "     16        \u001b[36m0.5363\u001b[0m       0.7250        \u001b[35m0.5310\u001b[0m  0.0148\n",
      "     17        0.5378       \u001b[32m0.7350\u001b[0m        \u001b[35m0.5263\u001b[0m  0.0149\n",
      "     18        0.5517       0.7250        0.5276  0.0155\n",
      "     19        0.5448       0.7250        0.5291  0.0159\n",
      "     20        \u001b[36m0.5280\u001b[0m       0.7350        \u001b[35m0.5247\u001b[0m  0.0147\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class subClass(ClassifierModule):\n",
    "    _hidden_neuron_cls = 5\n",
    "    \n",
    "class subsubClass(ClassifierModule):\n",
    "    _hidden_neuron_cls = 6\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "net2 = NeuralNetClassifier(\n",
    "    subClass,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "#     device='cuda',  # uncomment this to train with CUDA\n",
    ")\n",
    "\n",
    "net3 = NeuralNetClassifier(\n",
    "    subsubClass,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "#     device='cuda',  # uncomment this to train with CUDA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6933\u001b[0m       \u001b[32m0.5700\u001b[0m        \u001b[35m0.6852\u001b[0m  0.0145\n",
      "      2        \u001b[36m0.6855\u001b[0m       \u001b[32m0.6200\u001b[0m        \u001b[35m0.6736\u001b[0m  0.0174\n",
      "      3        \u001b[36m0.6777\u001b[0m       0.6200        \u001b[35m0.6663\u001b[0m  0.0134\n",
      "      4        \u001b[36m0.6603\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m0.6597\u001b[0m  0.0159\n",
      "      5        \u001b[36m0.6560\u001b[0m       \u001b[32m0.6650\u001b[0m        \u001b[35m0.6524\u001b[0m  0.0159\n",
      "      6        \u001b[36m0.6534\u001b[0m       0.6600        \u001b[35m0.6465\u001b[0m  0.0159\n",
      "      7        \u001b[36m0.6490\u001b[0m       0.6650        \u001b[35m0.6393\u001b[0m  0.0164\n",
      "      8        \u001b[36m0.6305\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m0.6305\u001b[0m  0.0146\n",
      "      9        \u001b[36m0.6270\u001b[0m       \u001b[32m0.6800\u001b[0m        \u001b[35m0.6202\u001b[0m  0.0135\n",
      "     10        \u001b[36m0.6222\u001b[0m       0.6750        \u001b[35m0.6114\u001b[0m  0.0697\n",
      "     11        \u001b[36m0.6110\u001b[0m       0.6800        \u001b[35m0.6038\u001b[0m  0.0150\n",
      "     12        \u001b[36m0.6006\u001b[0m       \u001b[32m0.7000\u001b[0m        \u001b[35m0.5973\u001b[0m  0.0147\n",
      "     13        0.6030       0.7000        \u001b[35m0.5921\u001b[0m  0.0166\n",
      "     14        \u001b[36m0.5913\u001b[0m       0.7000        \u001b[35m0.5848\u001b[0m  0.0161\n",
      "     15        \u001b[36m0.5791\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.5795\u001b[0m  0.0154\n",
      "     16        \u001b[36m0.5694\u001b[0m       0.7100        \u001b[35m0.5728\u001b[0m  0.0156\n",
      "     17        0.5824       0.7050        \u001b[35m0.5701\u001b[0m  0.0180\n",
      "     18        \u001b[36m0.5686\u001b[0m       0.7050        \u001b[35m0.5683\u001b[0m  0.0171\n",
      "     19        \u001b[36m0.5460\u001b[0m       0.7100        \u001b[35m0.5623\u001b[0m  0.0141\n",
      "     20        \u001b[36m0.5459\u001b[0m       0.7150        \u001b[35m0.5588\u001b[0m  0.0157\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6957\u001b[0m       \u001b[32m0.5650\u001b[0m        \u001b[35m0.6862\u001b[0m  0.0147\n",
      "      2        \u001b[36m0.6857\u001b[0m       0.5650        \u001b[35m0.6761\u001b[0m  0.0142\n",
      "      3        \u001b[36m0.6713\u001b[0m       \u001b[32m0.6300\u001b[0m        \u001b[35m0.6663\u001b[0m  0.0160\n",
      "      4        \u001b[36m0.6632\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m0.6584\u001b[0m  0.0161\n",
      "      5        \u001b[36m0.6539\u001b[0m       0.6250        \u001b[35m0.6499\u001b[0m  0.0140\n",
      "      6        \u001b[36m0.6283\u001b[0m       0.6300        \u001b[35m0.6367\u001b[0m  0.0158\n",
      "      7        0.6297       \u001b[32m0.6550\u001b[0m        \u001b[35m0.6286\u001b[0m  0.0142\n",
      "      8        \u001b[36m0.6163\u001b[0m       0.6500        \u001b[35m0.6202\u001b[0m  0.0144\n",
      "      9        \u001b[36m0.5967\u001b[0m       \u001b[32m0.6750\u001b[0m        \u001b[35m0.6082\u001b[0m  0.0149\n",
      "     10        \u001b[36m0.5935\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.5962\u001b[0m  0.0140\n",
      "     11        0.6030       \u001b[32m0.7050\u001b[0m        \u001b[35m0.5876\u001b[0m  0.0160\n",
      "     12        \u001b[36m0.5686\u001b[0m       \u001b[32m0.7250\u001b[0m        \u001b[35m0.5764\u001b[0m  0.0145\n",
      "     13        0.5702       \u001b[32m0.7350\u001b[0m        \u001b[35m0.5722\u001b[0m  0.0143\n",
      "     14        \u001b[36m0.5572\u001b[0m       0.7350        \u001b[35m0.5625\u001b[0m  0.0150\n",
      "     15        0.5633       0.7350        \u001b[35m0.5618\u001b[0m  0.0144\n",
      "     16        0.5627       0.7350        \u001b[35m0.5544\u001b[0m  0.0147\n",
      "     17        \u001b[36m0.5494\u001b[0m       0.7350        \u001b[35m0.5496\u001b[0m  0.0154\n",
      "     18        \u001b[36m0.5418\u001b[0m       0.7300        \u001b[35m0.5450\u001b[0m  0.0158\n",
      "     19        0.5421       \u001b[32m0.7500\u001b[0m        0.5454  0.0145\n",
      "     20        \u001b[36m0.5313\u001b[0m       0.7500        \u001b[35m0.5392\u001b[0m  0.0144\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=subsubClass(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.fit(X, y)\n",
    "net3.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, as in `sklearn`, you may call `predict` or `predict_proba` on the fitted model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions, classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net.predict(X[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5603605 , 0.4396395 ],\n",
       "       [0.782588  , 0.21741197],\n",
       "       [0.6924924 , 0.3075076 ],\n",
       "       [0.8895971 , 0.1104029 ],\n",
       "       [0.70746267, 0.2925373 ]], dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = net.predict_proba(X[:5])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training a regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A toy regression task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_regr, y_regr = make_regression(1000, 20, n_informative=10, random_state=0)\n",
    "X_regr = X_regr.astype(np.float32)\n",
    "y_regr = y_regr.astype(np.float32) / 100\n",
    "y_regr = y_regr.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 20), (1000, 1), -6.4901485, 6.154505)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_regr.shape, y_regr.shape, y_regr.min(), y_regr.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: Regression currently requires the target to be 2-dimensional, hence the need to reshape. This should be fixed with an upcoming version of pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition of the `pytorch` regression `module`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, define a vanilla neural network with two hidden layers. The main difference is that the output layer only has one unit and does not apply a softmax nonlinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10,\n",
    "            nonlin=F.relu,\n",
    "    ):\n",
    "        super(RegressorModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = self.output(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining and training the neural net regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training a regressor is almost the same as training a classifier. Mainly, we use `NeuralNetRegressor` instead of `NeuralNetClassifier` (this is the same terminology as in `sklearn`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_regr = NeuralNetRegressor(\n",
    "    RegressorModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "#     device='cuda',  # uncomment this to train with CUDA\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.3479\u001b[0m        \u001b[32m3.0639\u001b[0m  0.0383\n",
      "      2        \u001b[36m1.7830\u001b[0m        \u001b[32m0.5272\u001b[0m  0.0148\n",
      "      3        \u001b[36m0.2620\u001b[0m        \u001b[32m0.1964\u001b[0m  0.0170\n",
      "      4        \u001b[36m0.1332\u001b[0m        \u001b[32m0.1704\u001b[0m  0.0163\n",
      "      5        \u001b[36m0.1209\u001b[0m        \u001b[32m0.1355\u001b[0m  0.0168\n",
      "      6        0.2293        0.5582  0.0182\n",
      "      7        0.3251        \u001b[32m0.1058\u001b[0m  0.0177\n",
      "      8        \u001b[36m0.0747\u001b[0m        \u001b[32m0.0565\u001b[0m  0.0156\n",
      "      9        \u001b[36m0.0347\u001b[0m        \u001b[32m0.0419\u001b[0m  0.0168\n",
      "     10        \u001b[36m0.0299\u001b[0m        \u001b[32m0.0309\u001b[0m  0.0156\n",
      "     11        \u001b[36m0.0202\u001b[0m        0.0358  0.0167\n",
      "     12        0.0328        0.0310  0.0168\n",
      "     13        0.0290        0.0599  0.0173\n",
      "     14        0.0635        0.0513  0.0170\n",
      "     15        0.0502        0.0602  0.0164\n",
      "     16        0.0475        \u001b[32m0.0221\u001b[0m  0.0161\n",
      "     17        \u001b[36m0.0168\u001b[0m        0.0288  0.0165\n",
      "     18        0.0208        \u001b[32m0.0132\u001b[0m  0.0153\n",
      "     19        \u001b[36m0.0089\u001b[0m        0.0196  0.0166\n",
      "     20        0.0138        \u001b[32m0.0109\u001b[0m  0.0165\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=RegressorModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_regr.fit(X_regr, y_regr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions, regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may call `predict` or `predict_proba` on the fitted model. For regressions, both methods return the same value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.8809004 ],\n",
       "       [-1.4545293 ],\n",
       "       [-0.73125255],\n",
       "       [-0.21497256],\n",
       "       [-0.3453628 ]], dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net_regr.predict(X_regr[:5])\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving and loading a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save and load either the whole model by using pickle or just the learned model parameters by calling `save_params` and `load_params`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving the whole model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = '/tmp/mymodel.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'wb') as f:\n",
    "    pickle.dump(net, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(file_name, 'rb') as f:\n",
    "    new_net = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving only the model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only saves and loads the proper `module` parameters, meaning that hyperparameters such as `lr` and `max_epochs` are not saved. Therefore, to load the model, we have to re-initialize it beforehand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.save_params(f_params=file_name)  # a file handler also works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first initialize the model\n",
    "new_net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    ").initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_net.load_params(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage with an `sklearn Pipeline`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to put the `NeuralNetClassifier` inside an `sklearn Pipeline`, as you would with any `sklearn` classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('net', net),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module.\n",
      "Re-initializing criterion.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6861\u001b[0m       \u001b[32m0.5700\u001b[0m        \u001b[35m0.6835\u001b[0m  0.0134\n",
      "      2        \u001b[36m0.6831\u001b[0m       \u001b[32m0.5950\u001b[0m        \u001b[35m0.6811\u001b[0m  0.0140\n",
      "      3        \u001b[36m0.6798\u001b[0m       0.5900        \u001b[35m0.6782\u001b[0m  0.0154\n",
      "      4        \u001b[36m0.6766\u001b[0m       \u001b[32m0.6050\u001b[0m        \u001b[35m0.6751\u001b[0m  0.0149\n",
      "      5        \u001b[36m0.6751\u001b[0m       0.6050        \u001b[35m0.6715\u001b[0m  0.0154\n",
      "      6        \u001b[36m0.6656\u001b[0m       \u001b[32m0.6450\u001b[0m        \u001b[35m0.6663\u001b[0m  0.0158\n",
      "      7        \u001b[36m0.6641\u001b[0m       0.6250        \u001b[35m0.6607\u001b[0m  0.0146\n",
      "      8        \u001b[36m0.6532\u001b[0m       0.6400        \u001b[35m0.6540\u001b[0m  0.0162\n",
      "      9        \u001b[36m0.6524\u001b[0m       \u001b[32m0.6500\u001b[0m        \u001b[35m0.6474\u001b[0m  0.0149\n",
      "     10        \u001b[36m0.6399\u001b[0m       \u001b[32m0.6650\u001b[0m        \u001b[35m0.6408\u001b[0m  0.0140\n",
      "     11        0.6420       \u001b[32m0.6700\u001b[0m        \u001b[35m0.6342\u001b[0m  0.0140\n",
      "     12        \u001b[36m0.6283\u001b[0m       0.6650        \u001b[35m0.6271\u001b[0m  0.0156\n",
      "     13        \u001b[36m0.6204\u001b[0m       \u001b[32m0.6750\u001b[0m        \u001b[35m0.6190\u001b[0m  0.0150\n",
      "     14        \u001b[36m0.6030\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.6110\u001b[0m  0.0145\n",
      "     15        0.6108       \u001b[32m0.7250\u001b[0m        \u001b[35m0.6068\u001b[0m  0.0148\n",
      "     16        0.6037       0.7250        \u001b[35m0.5997\u001b[0m  0.0151\n",
      "     17        \u001b[36m0.5945\u001b[0m       0.7150        \u001b[35m0.5945\u001b[0m  0.0156\n",
      "     18        \u001b[36m0.5793\u001b[0m       0.7200        \u001b[35m0.5883\u001b[0m  0.0153\n",
      "     19        0.5886       0.7250        \u001b[35m0.5844\u001b[0m  0.0162\n",
      "     20        \u001b[36m0.5784\u001b[0m       0.7250        \u001b[35m0.5808\u001b[0m  0.0139\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;net&#x27;,\n",
       "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       "))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;scale&#x27;, StandardScaler()),\n",
       "                (&#x27;net&#x27;,\n",
       "                 &lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       "))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('scale', StandardScaler()),\n",
       "                ('net',\n",
       "                 <class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       "))])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.36018655, 0.6398134 ],\n",
       "       [0.694329  , 0.30567098],\n",
       "       [0.66123945, 0.3387605 ],\n",
       "       [0.7088052 , 0.2911948 ],\n",
       "       [0.6906064 , 0.3093936 ]], dtype=float32)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_proba = pipe.predict_proba(X[:5])\n",
    "y_proba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To save the whole pipeline, including the pytorch module, use `pickle`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a new callback to the model is straightforward. Below we show how to add a new callback that determines the area under the ROC (AUC) score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import EpochScoring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a scoring callback in skorch, `EpochScoring`, which we use for this. We have to specify which score to calculate. We have 3 choices:\n",
    "\n",
    "* Passing a string: This should be a valid `sklearn` metric. For a list of all existing scores, look [here](http://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics).\n",
    "* Passing `None`: If you implement your own `.score` method on your neural net, passing `scoring=None` will tell `skorch` to use that.\n",
    "* Passing a function or callable: If we want to define our own scoring function, we pass a function with the signature `func(model, X, y) -> score`, which is then used.\n",
    "\n",
    "Note that this works exactly the same as scoring in `sklearn` does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our case here, since `sklearn` already implements AUC, we just pass the correct string `'roc_auc'`. We should also tell the callback that higher scores are better (to get the correct colors printed below -- by default, lower scores are assumed to be better). Furthermore, we may specify a `name` argument for `EpochScoring`, and whether to use training data (by setting `on_train=True`) or validation data (which is the default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc = EpochScoring(scoring='roc_auc', lower_is_better=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we pass the scoring callback to the `callbacks` parameter as a list and then call `fit`. Notice that we get the printed scores and color highlighting for free."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    callbacks=[auc],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    roc_auc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ---------  ------------  -----------  ------------  ------\n",
      "      1     \u001b[36m0.7071\u001b[0m        \u001b[32m0.6925\u001b[0m       \u001b[35m0.6150\u001b[0m        \u001b[31m0.6777\u001b[0m  0.0146\n",
      "      2     \u001b[36m0.7544\u001b[0m        \u001b[32m0.6772\u001b[0m       \u001b[35m0.6450\u001b[0m        \u001b[31m0.6673\u001b[0m  0.0129\n",
      "      3     \u001b[36m0.7713\u001b[0m        \u001b[32m0.6729\u001b[0m       \u001b[35m0.6800\u001b[0m        \u001b[31m0.6572\u001b[0m  0.0149\n",
      "      4     \u001b[36m0.7810\u001b[0m        \u001b[32m0.6666\u001b[0m       \u001b[35m0.6900\u001b[0m        \u001b[31m0.6496\u001b[0m  0.0136\n",
      "      5     \u001b[36m0.7865\u001b[0m        \u001b[32m0.6490\u001b[0m       0.6850        \u001b[31m0.6383\u001b[0m  0.0148\n",
      "      6     \u001b[36m0.7930\u001b[0m        0.6538       0.6900        \u001b[31m0.6301\u001b[0m  0.0151\n",
      "      7     0.7903        \u001b[32m0.6335\u001b[0m       0.6900        \u001b[31m0.6170\u001b[0m  0.0152\n",
      "      8     0.7881        \u001b[32m0.6131\u001b[0m       0.6900        \u001b[31m0.6022\u001b[0m  0.0161\n",
      "      9     0.7891        \u001b[32m0.6049\u001b[0m       \u001b[35m0.7000\u001b[0m        \u001b[31m0.5900\u001b[0m  0.0137\n",
      "     10     0.7900        \u001b[32m0.6038\u001b[0m       \u001b[35m0.7050\u001b[0m        \u001b[31m0.5813\u001b[0m  0.0152\n",
      "     11     0.7893        \u001b[32m0.5842\u001b[0m       0.7050        \u001b[31m0.5725\u001b[0m  0.0152\n",
      "     12     0.7905        0.5899       \u001b[35m0.7200\u001b[0m        \u001b[31m0.5665\u001b[0m  0.0155\n",
      "     13     0.7894        \u001b[32m0.5654\u001b[0m       \u001b[35m0.7300\u001b[0m        \u001b[31m0.5589\u001b[0m  0.0141\n",
      "     14     \u001b[36m0.7975\u001b[0m        0.5707       \u001b[35m0.7400\u001b[0m        \u001b[31m0.5529\u001b[0m  0.0148\n",
      "     15     \u001b[36m0.8012\u001b[0m        \u001b[32m0.5567\u001b[0m       0.7250        \u001b[31m0.5452\u001b[0m  0.0152\n",
      "     16     \u001b[36m0.8062\u001b[0m        0.5705       0.7200        \u001b[31m0.5417\u001b[0m  0.0151\n",
      "     17     0.8062        \u001b[32m0.5310\u001b[0m       0.7150        \u001b[31m0.5361\u001b[0m  0.0151\n",
      "     18     \u001b[36m0.8069\u001b[0m        0.5403       0.7300        \u001b[31m0.5340\u001b[0m  0.0161\n",
      "     19     \u001b[36m0.8098\u001b[0m        \u001b[32m0.5215\u001b[0m       0.7200        \u001b[31m0.5325\u001b[0m  0.0148\n",
      "     20     0.8093        0.5217       0.7150        \u001b[31m0.5286\u001b[0m  0.0148\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For information on how to write custom callbacks, have a look at the [Advanced_Usage](https://nbviewer.jupyter.org/github/skorch-dev/skorch/blob/master/notebooks/Advanced_Usage.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Usage with sklearn `GridSearchCV`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special prefixes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `NeuralNet` class allows to directly access parameters of the `pytorch module` by using the `module__` prefix. So e.g. if you defined the `module` to have a `num_units` parameter, you can set it via the `module__num_units` argument. This is exactly the same logic that allows to access estimator parameters in `sklearn Pipeline`s and `FeatureUnion`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This feature is useful in several ways. For one, it allows to set those parameters in the model definition. Furthermore, it allows you to set parameters in an `sklearn GridSearchCV` as shown below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the parameters prefixed by `module__`, you may access a couple of other attributes, such as those of the optimizer by using the `optimizer__` prefix (again, see below). All those special prefixes are stored in the `prefixes_` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iterator_train, iterator_valid, callbacks, dataset, module, criterion, optimizer\n"
     ]
    }
   ],
   "source": [
    "print(', '.join(net.prefixes_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing a grid search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we show how to perform a grid search over the learning rate (`lr`), the module's number of hidden units (`module__num_units`), the module's dropout rate (`module__dropout`), and whether the SGD optimizer should use Nesterov momentum or not (`optimizer__nesterov`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    optimizer__momentum=0.9,\n",
    "    verbose=0,\n",
    "    train_split=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note*: We set the verbosity level to zero (`verbose=0`) to prevent too much print output from being shown. Also, we disable the skorch-internal train-validation split (`train_split=False`) because `GridSearchCV` already splits the training data for us. We only have to leave the skorch-internal split enabled for some specific uses, e.g. to perform `EarlyStopping`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\n",
    "    'lr': [0.05, 0.1],\n",
    "    'module__num_units': [10, 20],\n",
    "    'module__dropout': [0, 0.5],\n",
    "    'optimizer__nesterov': [False, True],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(net, params, refit=False, cv=3, scoring='accuracy', verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] END lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=False; total time=   0.3s\n",
      "[CV] END lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=True; total time=   0.3s\n",
      "[CV] END lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False; total time=   0.3s\n",
      "[CV] END lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True; total time=   0.2s\n",
      "[CV] END lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True; total time=   0.3s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.ClassifierModule&#x27;&gt;,\n",
       "),\n",
       "             param_grid={&#x27;lr&#x27;: [0.05, 0.1], &#x27;module__dropout&#x27;: [0, 0.5],\n",
       "                         &#x27;module__num_units&#x27;: [10, 20],\n",
       "                         &#x27;optimizer__nesterov&#x27;: [False, True]},\n",
       "             refit=False, scoring=&#x27;accuracy&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3,\n",
       "             estimator=&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.ClassifierModule&#x27;&gt;,\n",
       "),\n",
       "             param_grid={&#x27;lr&#x27;: [0.05, 0.1], &#x27;module__dropout&#x27;: [0, 0.5],\n",
       "                         &#x27;module__num_units&#x27;: [10, 20],\n",
       "                         &#x27;optimizer__nesterov&#x27;: [False, True]},\n",
       "             refit=False, scoring=&#x27;accuracy&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.ClassifierModule&#x27;&gt;,\n",
       ")</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">NeuralNetClassifier</label><div class=\"sk-toggleable__content\"><pre>&lt;class &#x27;skorch.classifier.NeuralNetClassifier&#x27;&gt;[uninitialized](\n",
       "  module=&lt;class &#x27;__main__.ClassifierModule&#x27;&gt;,\n",
       ")</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=<class '__main__.ClassifierModule'>,\n",
       "),\n",
       "             param_grid={'lr': [0.05, 0.1], 'module__dropout': [0, 0.5],\n",
       "                         'module__num_units': [10, 20],\n",
       "                         'optimizer__nesterov': [False, True]},\n",
       "             refit=False, scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8699897502292712 {'lr': 0.1, 'module__dropout': 0, 'module__num_units': 20, 'optimizer__nesterov': False}\n"
     ]
    }
   ],
   "source": [
    "print(gs.best_score_, gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, we could further nest the `NeuralNetClassifier` within an `sklearn Pipeline`, in which case we just prefix the parameter by the name of the net (e.g. `net__module__num_units`)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('teaching')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "2142a618935ee31125fbb97f06401dd4f60968dd5a549a21d575788564038767"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
